# MTD-GAN - Official Pytorch Implementation

It is currently incomplete. It will be updated in the future.

<p align="center"><img width="100%" src="figures/Graphical_Abstract.png" /></p>

## üí° Highlights
+ Develop a discriminator utilizing multi-task learning (MTL), which leverages three simultaneous tasks‚Äîrestoration, image-level decision, and pixel-level decision‚Äîto transfer contextual, global, and local feedback between the real normal-dose and synthesized images to the generator.

+ Propose two regulations to improve the representation capabilities of the discriminator: restoration consistency (RC), which compares the discriminator's outputs from the input data with the corresponding restoration data generated by our MTL discriminator for consistency, and non-difference suppression (NDS), which excludes areas that cause confusion in discriminator decisions.

+ Design a novel generator that consists of residual fast Fourier transform with convolution (Res-FFT-Conv) blocks that fuse frequency-spatial dual-domain representations. The proposed generator effectively captures rich information by simultaneously utilizing spatial (or local), spectral (or global), and residual connections. To the best of our knowledge, this represents an inaugural effort in employing the Res-FFT-Conv block within the generator for LDCT denoising, which demonstrates the versatility of the block.

+ Evaluate our network with extensive experiments, including an ablation study and visual scoring using two distinct datasets of brain and abdominal CT images. Six metrics based on pixel- and feature-spaces were used, and the results indicated superior performances in both quantitative and qualitative measures compared to those of state-of-the-art denoising techniques.




## Paper
This repository provides the official implementation code of MTD-GAN in the following paper:
<br/>Generative Adversarial Network with Robust Discriminator Through Multi-Task Learning for Low-Dose CT Denoising</b> 
<br/>[Sunggu Kyung](https://github.com/babbu3682), Jongjun Won, Seongyong Pak, Sunwoo Kim, Sangyoon Lee, Kanggil Park, Gil-Sun Hong, and Namkug Kim 
<br/>[MI2RL LAB](https://www.mi2rl.co/) <br/>
<br/>(Under revision...) IEEE Transactions on Medical Imaging (TMI) <br/>



## Requirements
+ Linux
+ CUDA 11.6
+ Python 3.8.5
+ Pytorch 1.13.1

## üì¶ MTD-GAN Framework
### 1. Clone the repository and install dependencies
```bash
$ git clone https://github.com/babbu3682/MTD-GAN.git
$ cd MTD-GAN/
$ pip install -r requirements.txt
```

### 2. Preparing data
#### Download the dataset from [this repository](https://www.aapm.org/grandchallenge/lowdosect/).

- The processed dataset directory structure
```
datasets/MAYO
    train
        |--  full_3mm
        |--  quarter_3mm
            |--  L067
            |--  L096
            |--  L109
            |--  L143
                    .
                    .
                    .
    valid
        |--  full_3mm
        |--  quarter_3mm
            |--  L333
                    .
                    .
                    .
    test
        |--  full_3mm
        |--  quarter_3mm
            |--  L506
                    .
                    .
                    .
```

### 3. Upstream

#### üìã To Do List
- [x] publish previous works' weights
- [x] publish our works' weights


**+ train**:
```bash
CUDA_VISIBLE_DEVICES=2 python -W ignore train.py \
--dataset 'mayo' \
--dataset-type-train 'window_patch' \
--dataset-type-valid 'window' \
--batch-size 20 \
--train-num-workers 16 \
--valid-num-workers 16 \
--model 'MTD_GAN_Method' \
--loss 'L1 Loss' \
--method 'pcgrad' \
--optimizer 'adamw' \
--scheduler 'poly_lr' \
--epochs 500 \
--warmup-epochs 10 \
--lr 1e-4 \
--min-lr 1e-6 \
--multi-gpu-mode 'Single' \
--device 'cuda' \
--print-freq 10 \
--save-checkpoint-every 1 \
--checkpoint-dir '/workspace/sunggu/4.Dose_img2img/MTD_GAN/checkpoints/abdomen/MTD_GAN' \
--save-dir '/workspace/sunggu/4.Dose_img2img/MTD_GAN/predictions/train/abdomen/MTD_GAN' \
--memo 'abdomen, 500 epoch, node 14'
```

**+ test**:
```bash
CUDA_VISIBLE_DEVICES=2 python -W ignore test.py \
--dataset 'mayo_test' \
--dataset-type-test 'window' \
--test-batch-size 1 \
--test-num-workers 16 \
--model 'MTD_GAN' \
--loss 'L1 Loss' \
--multi-gpu-mode 'Single' \
--device 'cuda' \
--print-freq 10 \
--checkpoint-dir '/workspace/sunggu/4.Dose_img2img/MTD_GAN/checkpoints/abdomen/MTD_GAN' \
--save-dir '/workspace/sunggu/4.Dose_img2img/MTD_GAN/predictions/test/abdomen/MTD_GAN' \
--resume "/workspace/sunggu/4.Dose_img2img/MTD_GAN/checkpoints/abdomen/MTD_GAN/epoch_77777_checkpoint.pth" \
--memo 'abdomen, node 14' \
--epoch 77777
```


## Excuse
For personal information security reasons of medical data in Korea, our data cannot be disclosed.


## üìù Citation
If you use this code for your research, please cite our papers:
```
‚è≥ It's scheduled to be uploaded soon.
```

## ü§ù Acknowledgement
We build MTD-GAN framework by referring to the released code at [qubvel/segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch) and [Project-MONAI/MONAI](https://github.com/Project-MONAI/MONAI). 
This is a patent-pending technology.

We acknowledge the open-source libraries, including the [Diffuser](https://github.com/huggingface/diffusers) and [MONAI Generative Models](https://github.com/Project-MONAI/GenerativeModels), which enabled valuable comparisons in this study, and we extend our thanks to the pioneering authors (e.g., [RED-CNN](https://github.com/SSinyu/RED-CNN), [EDCNN](https://github.com/workingcoder/EDCNN), [CTformer](https://github.com/wdayang/CTformer), [Restormer](https://github.com/swz30/Restormer), [WGAN_VGG](https://github.com/hyeongyuy/CT-WGAN_VGG_tensorflow), [MAP-NN](https://github.com/hmshan/MAP-NN), [DUGAN](https://github.com/Hzzone/DU-GAN)).

### üõ°Ô∏è License <a name="license"></a>
Project is distributed under [MIT License](https://github.com/babbu3682/MTD-GAN/blob/main/LICENSE)
